{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f9c3c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "909fdd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>station_id</th>\n",
       "      <th>PM25_Concentration</th>\n",
       "      <th>PM10_Concentration</th>\n",
       "      <th>NO2_Concentration</th>\n",
       "      <th>CO_Concentration</th>\n",
       "      <th>O3_Concentration</th>\n",
       "      <th>SO2_Concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>138.0</td>\n",
       "      <td>159.4</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50.8</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>1002</td>\n",
       "      <td>89.0</td>\n",
       "      <td>132.9</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>96.5</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  station_id  PM25_Concentration  PM10_Concentration  \\\n",
       "0  2014-05-01 00:00:00        1001               138.0               159.4   \n",
       "1  2014-05-01 00:00:00        1002                89.0               132.9   \n",
       "\n",
       "   NO2_Concentration  CO_Concentration  O3_Concentration  SO2_Concentration  \n",
       "0               56.3               0.9              50.8               17.2  \n",
       "1               30.5               0.8              96.5                7.6  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beijing_aq = pd.read_csv('beijing_aq_preprocessed.csv.gz')\n",
    "beijing_aq.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17e140f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>station_id</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>1002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  station_id  weather  temperature  humidity  \\\n",
       "0  2014-05-01 00:00:00        1001      0.0         20.0      56.0   \n",
       "1  2014-05-01 00:00:00        1002      0.0         20.0      56.0   \n",
       "\n",
       "   wind_speed  wind_direction  \n",
       "0        7.92            13.0  \n",
       "1        7.92            13.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beijing_met = pd.read_csv('beijing_met_preprocessed.csv.gz')\n",
    "beijing_met.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae283fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beijing_met['time'] = pd.to_datetime(beijing_met['time'])\n",
    "# beijing_aq['time'] = pd.to_datetime(beijing_aq['time'])\n",
    "# beijing_aq_plus_met2 = beijing_aq_plus_met.sort_values(by=['time', 'station_id'])\n",
    "# beijing_aq_plus_met2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c43abc2",
   "metadata": {},
   "source": [
    "### Asserting number of data entries per station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c230350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for station in beijing_aq_plus_met2.station_id.unique():\n",
    "#     tmp_df = beijing_aq_plus_met2[beijing_aq_plus_met2.station_id==station]\n",
    "#     assert tmp_df.shape == (8760, 13)\n",
    "methods = ['linear','slinear','quadratic','cubic','spline','akima']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ce46fa",
   "metadata": {},
   "source": [
    "### Method 1 : Avg of RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e1c9bffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:25<00:00,  1.22it/s]\n",
      "  0%|                                                                                           | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2880549335463727 1.2553435394418677 1.463775516240924 1.4972760216294518 1.553201714525396 1.2699705921441573\n",
      "temperature slinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [04:01<00:00,  7.80s/it]\n",
      "  0%|                                                                                           | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.355662841813643 7.278641911844814 8.984151486149889 9.233955428384323 9.17568295569436 7.3832641802767025\n",
      "humidity slinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [02:10<00:00,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3075697940423363 3.3022554011973266 4.136850466097549 4.295506203864383 4.116862366070366 3.4603106226575253\n",
      "wind_speed slinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cols in ['temperature','humidity','wind_speed']:\n",
    "    \n",
    "    alinear_loss,aslinear_loss,aquadratic_loss,acubic_loss,aspline_loss,aakima_loss = [],[],[],[],[],[]\n",
    "    \n",
    "    for station in tqdm(beijing_met.station_id.unique()):\n",
    "        \n",
    "        linear_loss,slinear_loss,quadratic_loss,cubic_loss,spline_loss,akima_loss = [],[],[],[],[],[]\n",
    "        tmp_df = beijing_met[beijing_met.station_id==station].reset_index(drop=True)\n",
    "        assert tmp_df.shape == (8760, len(beijing_met.columns))\n",
    "        \n",
    "        tmp_df = tmp_df.iloc[:,[beijing_met.columns.get_loc('time'),beijing_met.columns.get_loc(cols)]]\n",
    "        \n",
    "        dates = pd.to_datetime([datetime.fromisoformat(tmp_df.iloc[i,tmp_df.columns.get_loc('time')]) for i in range(len(tmp_df))])\n",
    "        time_differences = ((dates - dates[0]).total_seconds() // 3600)\n",
    "        tmp_df['delta_t'] = time_differences\n",
    "        tmp_df = tmp_df.drop(columns='time')\n",
    "        \n",
    "        tmp_df_notmissing = tmp_df.dropna(subset=[cols]).reset_index(drop=True)\n",
    "        indices = ShuffleSplit(n_splits=5, test_size=.2, random_state=0).split(tmp_df_notmissing)\n",
    "        \n",
    "        for i in indices:\n",
    "            train_indices = list(i[0])\n",
    "            test_indices = list(i[1])\n",
    "            train_indices.sort(),test_indices.sort()\n",
    "   \n",
    "            xtest = tmp_df_notmissing.iloc[test_indices,:]\n",
    "            xtest = xtest.set_index('delta_t')\n",
    "            xtrain = tmp_df_notmissing.copy()\n",
    "            xtrain.iloc[test_indices,xtrain.columns.get_loc(cols)] = np.nan\n",
    "            xtrain = xtrain.set_index('delta_t')\n",
    "            \n",
    "            interpolate_linear = xtrain.interpolate(method='linear')\n",
    "            interpolate_linear = interpolate_linear.ffill()\n",
    "            interpolate_linear = interpolate_linear.bfill()\n",
    "            \n",
    "            interpolate_slinear = xtrain.interpolate(method='slinear')\n",
    "            interpolate_slinear = interpolate_slinear.ffill()\n",
    "            interpolate_slinear = interpolate_slinear.bfill()\n",
    "            \n",
    "            interpolate_quadratic = xtrain.interpolate(method='quadratic')\n",
    "            interpolate_quadratic = interpolate_quadratic.ffill()\n",
    "            interpolate_quadratic = interpolate_quadratic.bfill()\n",
    "            \n",
    "            interpolate_cubic = xtrain.interpolate(method='cubic')\n",
    "            interpolate_cubic = interpolate_cubic.ffill()\n",
    "            interpolate_cubic = interpolate_cubic.bfill()\n",
    "            \n",
    "            interpolate_spline = xtrain.interpolate(method='spline',order=3)\n",
    "            interpolate_spline = interpolate_spline.ffill()\n",
    "            interpolate_spline = interpolate_spline.bfill()\n",
    "            \n",
    "            interpolate_akima = xtrain.interpolate(method='akima')\n",
    "            interpolate_akima = interpolate_akima.ffill()\n",
    "            interpolate_akima = interpolate_akima.bfill()\n",
    "\n",
    "            mse_linear = mean_squared_error(xtest,interpolate_linear.iloc[test_indices,0],squared=False)\n",
    "            mse_slinear = mean_squared_error(xtest,interpolate_slinear.iloc[test_indices,0],squared=False)\n",
    "            mse_quadratic = mean_squared_error(xtest,interpolate_quadratic.iloc[test_indices,0],squared=False)\n",
    "            mse_cubic = mean_squared_error(xtest,interpolate_cubic.iloc[test_indices,0],squared=False)\n",
    "            mse_spline = mean_squared_error(xtest,interpolate_spline.iloc[test_indices,0],squared=False)\n",
    "            mse_akima = mean_squared_error(xtest,interpolate_akima.iloc[test_indices,0],squared=False)\n",
    "            \n",
    "            linear_loss.append(mse_linear),slinear_loss.append(mse_slinear),quadratic_loss.append(mse_quadratic),cubic_loss.append(mse_cubic)\n",
    "            spline_loss.append(mse_spline),akima_loss.append(mse_akima)\n",
    "            \n",
    "        alinear_loss.append(np.mean(mse_linear)),aslinear_loss.append(np.mean(mse_slinear)),aquadratic_loss.append(np.mean(mse_quadratic)),acubic_loss.append(np.mean(mse_cubic))\n",
    "        aspline_loss.append(np.mean(mse_spline)),aakima_loss.append(np.mean(mse_akima))\n",
    "        \n",
    "    print(np.mean(alinear_loss),np.mean(aslinear_loss),np.mean(aquadratic_loss),np.mean(acubic_loss),np.mean(aspline_loss),np.mean(aakima_loss))\n",
    "    method = methods[np.argmin(np.array([np.mean(alinear_loss),np.mean(aslinear_loss),np.mean(aquadratic_loss),np.mean(acubic_loss),np.mean(aspline_loss),np.mean(aakima_loss)]))]\n",
    "    print(cols,method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8bd57926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [06:01<00:00, 11.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.650657927097026 16.750067359559136 19.745632065530536 20.009703052003655 20.74208660150826 16.546232752415225\n",
      "PM25_Concentration akima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cols in ['PM25_Concentration']:\n",
    "    \n",
    "    alinear_loss,aslinear_loss,aquadratic_loss,acubic_loss,aspline_loss,aakima_loss = [],[],[],[],[],[]\n",
    "    \n",
    "    for station in tqdm(beijing_aq.station_id.unique()):\n",
    "        \n",
    "        linear_loss,slinear_loss,quadratic_loss,cubic_loss,spline_loss,akima_loss = [],[],[],[],[],[]\n",
    "        tmp_df = beijing_aq[beijing_aq.station_id==station].reset_index(drop=True)\n",
    "        assert tmp_df.shape == (8760, len(beijing_aq.columns))\n",
    "        \n",
    "        tmp_df = tmp_df.iloc[:,[beijing_aq.columns.get_loc('time'),beijing_aq.columns.get_loc(cols)]]\n",
    "        \n",
    "        dates = pd.to_datetime([datetime.fromisoformat(tmp_df.iloc[i,tmp_df.columns.get_loc('time')]) for i in range(len(tmp_df))])\n",
    "        time_differences = ((dates - dates[0]).total_seconds() // 3600)\n",
    "        tmp_df['delta_t'] = time_differences\n",
    "        tmp_df = tmp_df.drop(columns='time')\n",
    "        \n",
    "        tmp_df_notmissing = tmp_df.dropna(subset=[cols]).reset_index(drop=True)\n",
    "        indices = ShuffleSplit(n_splits=5, test_size=.2, random_state=0).split(tmp_df_notmissing)\n",
    "        \n",
    "        for i in indices:\n",
    "            train_indices = list(i[0])\n",
    "            test_indices = list(i[1])\n",
    "            train_indices.sort(),test_indices.sort()\n",
    "   \n",
    "            xtest = tmp_df_notmissing.iloc[test_indices,:]\n",
    "            xtest = xtest.set_index('delta_t')\n",
    "            xtrain = tmp_df_notmissing.copy()\n",
    "            xtrain.iloc[test_indices,xtrain.columns.get_loc(cols)] = np.nan\n",
    "            xtrain = xtrain.set_index('delta_t')\n",
    "            \n",
    "            interpolate_linear = xtrain.interpolate(method='linear')\n",
    "            interpolate_linear = interpolate_linear.ffill()\n",
    "            interpolate_linear = interpolate_linear.bfill()\n",
    "            \n",
    "            interpolate_slinear = xtrain.interpolate(method='slinear')\n",
    "            interpolate_slinear = interpolate_slinear.ffill()\n",
    "            interpolate_slinear = interpolate_slinear.bfill()\n",
    "            \n",
    "            interpolate_quadratic = xtrain.interpolate(method='quadratic')\n",
    "            interpolate_quadratic = interpolate_quadratic.ffill()\n",
    "            interpolate_quadratic = interpolate_quadratic.bfill()\n",
    "            \n",
    "            interpolate_cubic = xtrain.interpolate(method='cubic')\n",
    "            interpolate_cubic = interpolate_cubic.ffill()\n",
    "            interpolate_cubic = interpolate_cubic.bfill()\n",
    "            \n",
    "            interpolate_spline = xtrain.interpolate(method='spline',order=3)\n",
    "            interpolate_spline = interpolate_spline.ffill()\n",
    "            interpolate_spline = interpolate_spline.bfill()\n",
    "            \n",
    "            interpolate_akima = xtrain.interpolate(method='akima')\n",
    "            interpolate_akima = interpolate_akima.ffill()\n",
    "            interpolate_akima = interpolate_akima.bfill()\n",
    "\n",
    "            mse_linear = mean_squared_error(xtest,interpolate_linear.iloc[test_indices,0],squared=False)\n",
    "            mse_slinear = mean_squared_error(xtest,interpolate_slinear.iloc[test_indices,0],squared=False)\n",
    "            mse_quadratic = mean_squared_error(xtest,interpolate_quadratic.iloc[test_indices,0],squared=False)\n",
    "            mse_cubic = mean_squared_error(xtest,interpolate_cubic.iloc[test_indices,0],squared=False)\n",
    "            mse_spline = mean_squared_error(xtest,interpolate_spline.iloc[test_indices,0],squared=False)\n",
    "            mse_akima = mean_squared_error(xtest,interpolate_akima.iloc[test_indices,0],squared=False)\n",
    "            \n",
    "            linear_loss.append(mse_linear),slinear_loss.append(mse_slinear),quadratic_loss.append(mse_quadratic),cubic_loss.append(mse_cubic)\n",
    "            spline_loss.append(mse_spline),akima_loss.append(mse_akima)\n",
    "            \n",
    "        alinear_loss.append(np.mean(mse_linear)),aslinear_loss.append(np.mean(mse_slinear)),aquadratic_loss.append(np.mean(mse_quadratic)),acubic_loss.append(np.mean(mse_cubic))\n",
    "        aspline_loss.append(np.mean(mse_spline)),aakima_loss.append(np.mean(mse_akima))\n",
    "        \n",
    "    print(np.mean(alinear_loss),np.mean(aslinear_loss),np.mean(aquadratic_loss),np.mean(acubic_loss),np.mean(aspline_loss),np.mean(aakima_loss))\n",
    "    method = methods[np.argmin(np.array([np.mean(alinear_loss),np.mean(aslinear_loss),np.mean(aquadratic_loss),np.mean(acubic_loss),np.mean(aspline_loss),np.mean(aakima_loss)]))]\n",
    "    print(cols,method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be815c4",
   "metadata": {},
   "source": [
    "### Method 2 : Flatten and take RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9ec02c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.43s/it]\n",
      "  0%|                                                                                           | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature akima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [07:12<00:00, 13.94s/it]\n",
      "  0%|                                                                                           | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humidity slinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [03:16<00:00,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_speed slinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cols in ['temperature','humidity','wind_speed']:\n",
    "    \n",
    "    testing,ind = [],[]\n",
    "    linear_loss,slinear_loss,quadratic_loss,cubic_loss,spline_loss,akima_loss = [],[],[],[],[],[]\n",
    "    \n",
    "    for station in tqdm(beijing_met.station_id.unique()):\n",
    "        \n",
    "        \n",
    "        tmp_df = beijing_met[beijing_met.station_id==station].reset_index(drop=True)\n",
    "        assert tmp_df.shape == (8760, len(beijing_met.columns))\n",
    "        \n",
    "        tmp_df = tmp_df.iloc[:,[beijing_met.columns.get_loc('time'),beijing_met.columns.get_loc(cols)]]\n",
    "        \n",
    "        dates = pd.to_datetime([datetime.fromisoformat(tmp_df.iloc[i,tmp_df.columns.get_loc('time')]) for i in range(len(tmp_df))])\n",
    "        time_differences = ((dates - dates[0]).total_seconds() // 3600)\n",
    "        tmp_df['delta_t'] = time_differences\n",
    "        tmp_df = tmp_df.drop(columns='time')\n",
    "        \n",
    "        tmp_df_notmissing = tmp_df.dropna(subset=[cols]).reset_index(drop=True)\n",
    "        indices = ShuffleSplit(n_splits=5, test_size=.2, random_state=0).split(tmp_df_notmissing)\n",
    "        \n",
    "        for i in indices:\n",
    "            train_indices = list(i[0])\n",
    "            test_indices = list(i[1])\n",
    "            train_indices.sort(),test_indices.sort()\n",
    "   \n",
    "            xtest = tmp_df_notmissing.iloc[test_indices,:]\n",
    "            xtest = xtest.set_index('delta_t')\n",
    "            xtrain = tmp_df_notmissing.copy()\n",
    "            xtrain.iloc[test_indices,xtrain.columns.get_loc(cols)] = np.nan\n",
    "            xtrain = xtrain.set_index('delta_t')\n",
    "            \n",
    "            interpolate_linear = xtrain.interpolate(method='linear')\n",
    "            interpolate_linear = interpolate_linear.ffill()\n",
    "            interpolate_linear = interpolate_linear.bfill()\n",
    "            \n",
    "            interpolate_slinear = xtrain.interpolate(method='slinear')\n",
    "            interpolate_slinear = interpolate_slinear.ffill()\n",
    "            interpolate_slinear = interpolate_slinear.bfill()\n",
    "            \n",
    "            interpolate_quadratic = xtrain.interpolate(method='quadratic')\n",
    "            interpolate_quadratic = interpolate_quadratic.ffill()\n",
    "            interpolate_quadratic = interpolate_quadratic.bfill()\n",
    "            \n",
    "            interpolate_cubic = xtrain.interpolate(method='cubic')\n",
    "            interpolate_cubic = interpolate_cubic.ffill()\n",
    "            interpolate_cubic = interpolate_cubic.bfill()\n",
    "            \n",
    "            interpolate_spline = xtrain.interpolate(method='spline',order=3)\n",
    "            interpolate_spline = interpolate_spline.ffill()\n",
    "            interpolate_spline = interpolate_spline.bfill()\n",
    "            \n",
    "            interpolate_akima = xtrain.interpolate(method='akima')\n",
    "            interpolate_akima = interpolate_akima.ffill()\n",
    "            interpolate_akima = interpolate_akima.bfill()\n",
    "\n",
    "            \n",
    "            linear_loss.append(interpolate_linear.iloc[test_indices,0]),slinear_loss.append(interpolate_slinear.iloc[test_indices,0]),quadratic_loss.append(interpolate_quadratic.iloc[test_indices,0]),cubic_loss.append(interpolate_cubic.iloc[test_indices,0])\n",
    "            spline_loss.append(interpolate_spline.iloc[test_indices,0]),akima_loss.append(interpolate_akima.iloc[test_indices,0])\n",
    "            testing.append(xtest)\n",
    "    \n",
    "    interpolate_linear = list(np.concatenate(linear_loss).flat)\n",
    "    interpolate_slinear = list(np.concatenate(slinear_loss).flat)\n",
    "    interpolate_quadratic = list(np.concatenate(quadratic_loss).flat)\n",
    "    interpolate_cubic = list(np.concatenate(cubic_loss).flat)\n",
    "    interpolate_spline = list(np.concatenate(spline_loss).flat)\n",
    "    interpolate_akima = list(np.concatenate(akima_loss).flat)\n",
    "    \n",
    "    xtest = list(np.concatenate(testing).flat)\n",
    "#     print(xtest)\n",
    "    mse_linear = mean_squared_error(xtest,interpolate_linear,squared=False)\n",
    "    mse_slinear = mean_squared_error(xtest,interpolate_slinear,squared=False)\n",
    "    mse_quadratic = mean_squared_error(xtest,interpolate_quadratic,squared=False)\n",
    "    mse_cubic = mean_squared_error(xtest,interpolate_cubic,squared=False)\n",
    "    mse_spline = mean_squared_error(xtest,interpolate_spline,squared=False)\n",
    "    mse_akima = mean_squared_error(xtest,interpolate_akima,squared=False)\n",
    "            \n",
    "    method = methods[np.argmin(np.array([mse_linear,mse_slinear,mse_quadratic,mse_cubic,mse_spline,mse_akima]))]\n",
    "    print(cols,method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "26167525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [05:53<00:00, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM25_Concentration akima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cols in ['PM25_Concentration']:\n",
    "    \n",
    "    testing,ind = [],[]\n",
    "    linear_loss,slinear_loss,quadratic_loss,cubic_loss,spline_loss,akima_loss = [],[],[],[],[],[]\n",
    "    \n",
    "    for station in tqdm(beijing_aq.station_id.unique()):\n",
    "        \n",
    "        \n",
    "        tmp_df = beijing_aq[beijing_aq.station_id==station].reset_index(drop=True)\n",
    "        assert tmp_df.shape == (8760, len(beijing_aq.columns))\n",
    "        \n",
    "        tmp_df = tmp_df.iloc[:,[beijing_aq.columns.get_loc('time'),beijing_aq.columns.get_loc(cols)]]\n",
    "        \n",
    "        dates = pd.to_datetime([datetime.fromisoformat(tmp_df.iloc[i,tmp_df.columns.get_loc('time')]) for i in range(len(tmp_df))])\n",
    "        time_differences = ((dates - dates[0]).total_seconds() // 3600)\n",
    "        tmp_df['delta_t'] = time_differences\n",
    "        tmp_df = tmp_df.drop(columns='time')\n",
    "        \n",
    "        tmp_df_notmissing = tmp_df.dropna(subset=[cols]).reset_index(drop=True)\n",
    "        indices = ShuffleSplit(n_splits=5, test_size=.2, random_state=0).split(tmp_df_notmissing)\n",
    "        \n",
    "        for i in indices:\n",
    "            train_indices = list(i[0])\n",
    "            test_indices = list(i[1])\n",
    "            train_indices.sort(),test_indices.sort()\n",
    "   \n",
    "            xtest = tmp_df_notmissing.iloc[test_indices,:]\n",
    "            xtest = xtest.set_index('delta_t')\n",
    "            xtrain = tmp_df_notmissing.copy()\n",
    "            xtrain.iloc[test_indices,xtrain.columns.get_loc(cols)] = np.nan\n",
    "            xtrain = xtrain.set_index('delta_t')\n",
    "            \n",
    "            interpolate_linear = xtrain.interpolate(method='linear')\n",
    "            interpolate_linear = interpolate_linear.ffill()\n",
    "            interpolate_linear = interpolate_linear.bfill()\n",
    "            \n",
    "            interpolate_slinear = xtrain.interpolate(method='slinear')\n",
    "            interpolate_slinear = interpolate_slinear.ffill()\n",
    "            interpolate_slinear = interpolate_slinear.bfill()\n",
    "            \n",
    "            interpolate_quadratic = xtrain.interpolate(method='quadratic')\n",
    "            interpolate_quadratic = interpolate_quadratic.ffill()\n",
    "            interpolate_quadratic = interpolate_quadratic.bfill()\n",
    "            \n",
    "            interpolate_cubic = xtrain.interpolate(method='cubic')\n",
    "            interpolate_cubic = interpolate_cubic.ffill()\n",
    "            interpolate_cubic = interpolate_cubic.bfill()\n",
    "            \n",
    "            interpolate_spline = xtrain.interpolate(method='spline',order=3)\n",
    "            interpolate_spline = interpolate_spline.ffill()\n",
    "            interpolate_spline = interpolate_spline.bfill()\n",
    "            \n",
    "            interpolate_akima = xtrain.interpolate(method='akima')\n",
    "            interpolate_akima = interpolate_akima.ffill()\n",
    "            interpolate_akima = interpolate_akima.bfill()\n",
    "\n",
    "            \n",
    "            linear_loss.append(interpolate_linear.iloc[test_indices,0]),slinear_loss.append(interpolate_slinear.iloc[test_indices,0]),quadratic_loss.append(interpolate_quadratic.iloc[test_indices,0]),cubic_loss.append(interpolate_cubic.iloc[test_indices,0])\n",
    "            spline_loss.append(interpolate_spline.iloc[test_indices,0]),akima_loss.append(interpolate_akima.iloc[test_indices,0])\n",
    "            testing.append(xtest)\n",
    "    \n",
    "    interpolate_linear = list(np.concatenate(linear_loss).flat)\n",
    "    interpolate_slinear = list(np.concatenate(slinear_loss).flat)\n",
    "    interpolate_quadratic = list(np.concatenate(quadratic_loss).flat)\n",
    "    interpolate_cubic = list(np.concatenate(cubic_loss).flat)\n",
    "    interpolate_spline = list(np.concatenate(spline_loss).flat)\n",
    "    interpolate_akima = list(np.concatenate(akima_loss).flat)\n",
    "    \n",
    "    xtest = list(np.concatenate(testing).flat)\n",
    "#     print(xtest)\n",
    "    mse_linear = mean_squared_error(xtest,interpolate_linear,squared=False)\n",
    "    mse_slinear = mean_squared_error(xtest,interpolate_slinear,squared=False)\n",
    "    mse_quadratic = mean_squared_error(xtest,interpolate_quadratic,squared=False)\n",
    "    mse_cubic = mean_squared_error(xtest,interpolate_cubic,squared=False)\n",
    "    mse_spline = mean_squared_error(xtest,interpolate_spline,squared=False)\n",
    "    mse_akima = mean_squared_error(xtest,interpolate_akima,squared=False)\n",
    "            \n",
    "    method = methods[np.argmin(np.array([mse_linear,mse_slinear,mse_quadratic,mse_cubic,mse_spline,mse_akima]))]\n",
    "    print(cols,method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3a5923c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>station_id</th>\n",
       "      <th>PM25_Concentration</th>\n",
       "      <th>PM10_Concentration</th>\n",
       "      <th>NO2_Concentration</th>\n",
       "      <th>CO_Concentration</th>\n",
       "      <th>O3_Concentration</th>\n",
       "      <th>SO2_Concentration</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>159.4</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-01 01:00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>163.9</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>51.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-05-01 02:00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>148.4</td>\n",
       "      <td>55.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.76</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-05-01 03:00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>145.6</td>\n",
       "      <td>65.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-01 04:00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>119.3</td>\n",
       "      <td>66.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271555</th>\n",
       "      <td>2015-04-30 19:00:00</td>\n",
       "      <td>1036</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>104.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>180.7</td>\n",
       "      <td>18.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271556</th>\n",
       "      <td>2015-04-30 20:00:00</td>\n",
       "      <td>1036</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>141.2</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>146.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271557</th>\n",
       "      <td>2015-04-30 21:00:00</td>\n",
       "      <td>1036</td>\n",
       "      <td>96.064103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271558</th>\n",
       "      <td>2015-04-30 22:00:00</td>\n",
       "      <td>1036</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>120.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271559</th>\n",
       "      <td>2015-04-30 23:00:00</td>\n",
       "      <td>1036</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271560 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  station_id  PM25_Concentration  \\\n",
       "0       2014-05-01 00:00:00        1001          138.000000   \n",
       "1       2014-05-01 01:00:00        1001          124.000000   \n",
       "2       2014-05-01 02:00:00        1001          127.000000   \n",
       "3       2014-05-01 03:00:00        1001          129.000000   \n",
       "4       2014-05-01 04:00:00        1001          119.000000   \n",
       "...                     ...         ...                 ...   \n",
       "271555  2015-04-30 19:00:00        1036           77.000000   \n",
       "271556  2015-04-30 20:00:00        1036           94.000000   \n",
       "271557  2015-04-30 21:00:00        1036           96.064103   \n",
       "271558  2015-04-30 22:00:00        1036           88.000000   \n",
       "271559  2015-04-30 23:00:00        1036           88.000000   \n",
       "\n",
       "        PM10_Concentration  NO2_Concentration  CO_Concentration  \\\n",
       "0                    159.4               56.3               0.9   \n",
       "1                    163.9               38.7               0.9   \n",
       "2                    148.4               55.6               1.0   \n",
       "3                    145.6               65.7               1.0   \n",
       "4                    119.3               66.9               1.0   \n",
       "...                    ...                ...               ...   \n",
       "271555               104.6               15.5               0.5   \n",
       "271556               141.2               26.1               0.6   \n",
       "271557                 NaN                NaN               NaN   \n",
       "271558                 NaN               23.0               0.7   \n",
       "271559                 NaN                NaN               NaN   \n",
       "\n",
       "        O3_Concentration  SO2_Concentration  weather  temperature  humidity  \\\n",
       "0                   50.8               17.2      0.0         20.0      56.0   \n",
       "1                   51.1               17.9      0.0         18.0      64.0   \n",
       "2                   27.2               16.6      0.0         18.0      70.0   \n",
       "3                    9.7               16.7      0.0         17.0      74.0   \n",
       "4                    2.0               16.5      0.0         17.0      75.0   \n",
       "...                  ...                ...      ...          ...       ...   \n",
       "271555             180.7               18.3      5.0         25.2      48.0   \n",
       "271556             146.1               16.9      5.0         25.0      47.0   \n",
       "271557               NaN                NaN      5.0         24.7      47.0   \n",
       "271558             120.6               15.8      5.0         24.4      47.0   \n",
       "271559               NaN                NaN      1.0         19.8      72.0   \n",
       "\n",
       "        wind_speed  wind_direction  \n",
       "0             7.92            13.0  \n",
       "1             7.56            13.0  \n",
       "2             5.76            13.0  \n",
       "3             6.12            13.0  \n",
       "4             4.68             1.0  \n",
       "...            ...             ...  \n",
       "271555        2.60            23.0  \n",
       "271556        3.50            23.0  \n",
       "271557        3.10            23.0  \n",
       "271558        2.70            23.0  \n",
       "271559        2.60            23.0  \n",
       "\n",
       "[271560 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "station_wise_met_df,station_wise_aq_df = [],[]\n",
    "best_methods = {'PM25_Concentration': 'akima', \n",
    "                'temperature': 'slinear',\n",
    "                'humidity': 'slinear', \n",
    "                'wind_speed': 'slinear',\n",
    "                'weather': 'nearest',\n",
    "                'wind_direction': 'nearest'}\n",
    "for station in beijing_met.station_id.unique():\n",
    "    tmp_df = beijing_met[beijing_met.station_id == station]\n",
    "    for cols in beijing_met.columns:\n",
    "        try:\n",
    "            tmp_df[cols] = tmp_df[cols].interpolate(best_methods[cols]).ffill().bfill()\n",
    "        except:\n",
    "            continue\n",
    "    station_wise_met_df.append(tmp_df)\n",
    "    tmp_df = beijing_aq[beijing_aq.station_id == station]\n",
    "    for cols in beijing_aq.columns:\n",
    "        try:\n",
    "            tmp_df[cols] = tmp_df[cols].interpolate(best_methods[cols]).ffill().bfill()\n",
    "        except:\n",
    "            continue\n",
    "    station_wise_aq_df.append(tmp_df)\n",
    "    \n",
    "filled_df_met = pd.concat(station_wise_met_df)\n",
    "filled_df_aq = pd.concat(station_wise_aq_df)\n",
    "\n",
    "merged_aq_met = pd.merge(filled_df_aq,filled_df_met)\n",
    "display(merged_aq_met)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
